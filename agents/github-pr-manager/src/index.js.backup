// agents/github-pr-manager/src/index.js
import express from "express";
import crypto from "crypto";
import { createClient } from "redis";
import { Octokit } from "octokit";
import { AIService } from "./ai-service.js";

const app = express();
const PORT = process.env.PORT ? Number(process.env.PORT) : 3001;
const REPO = process.env.GITHUB_REPOSITORY || "";
const TOKEN = process.env.GITHUB_TOKEN;
const WEBHOOK_SECRET = process.env.WEBHOOK_SECRET || "";
const PROMOTE_DRAFTS = (process.env.PROMOTE_DRAFTS || "false").toLowerCase() === "true";
const AI_SERVICE_URL = process.env.AI_SERVICE_URL || "http://localhost:8000";
const ENABLE_AI_ANALYSIS = (process.env.ENABLE_AI_ANALYSIS || "true").toLowerCase() === "true";

function safeLog(...args) {
  // Avoid logging secrets
  console.log(new Date().toISOString(), ...args);
}

if (!TOKEN) {
  safeLog("Warning: GITHUB_TOKEN not provided. Agent will not perform write actions.");
}

const octokit = new Octokit({ auth: TOKEN });
const aiService = new AIService(AI_SERVICE_URL);

// Redis client for webhook queue management
const redisClient = createClient({
  url: process.env.REDIS_URL || 'redis://localhost:6379'
});

// Initialize Redis connection
redisClient.on('error', (err) => safeLog('Redis Client Error:', err));
redisClient.on('connect', () => safeLog('Redis connected successfully'));

// Webhook processing statistics
const webhookStats = {
  processed: 0,
  queued: 0,
  failed: 0,
  lastProcessed: null
};

app.use(express.json({
  verify: (req, res, buf) => {
    // keep raw body for signature verification
    req.rawBody = buf;
  }
}));

app.get("/health", (req, res) => {
  res.json({
    status: "healthy",
    timestamp: new Date().toISOString(),
    repo: REPO || null,
    mode: process.env.NODE_ENV || "development",
    ai_enabled: ENABLE_AI_ANALYSIS,
    ai_service: AI_SERVICE_URL,
    redis_connected: redisClient.isOpen
  });
});

// Webhook processing status endpoint
app.get("/webhook/status", async (req, res) => {
  try {
    let queueSize = 0;
    let processingCount = 0;
    
    if (redisClient.isOpen) {
      queueSize = await redisClient.zCard('github:webhooks:queue');
      processingCount = await redisClient.hLen('github:webhooks:processing');
    }
    
    res.json({
      status: "operational",
      timestamp: new Date().toISOString(),
      statistics: webhookStats,
      queue: {
        pending: queueSize,
        processing: processingCount
      },
      redis_connected: redisClient.isOpen
    });
  } catch (error) {
    res.status(500).json({
      status: "error",
      error: error.message,
      timestamp: new Date().toISOString()
    });
  }
});

// Get specific webhook processing status
app.get("/webhook/status/:delivery", async (req, res) => {
  try {
    const delivery = req.params.delivery;
    
    if (!redisClient.isOpen) {
      return res.status(503).json({ error: "Redis not connected" });
    }
    
    const status = await redisClient.hGet('github:webhooks:processing', delivery);
    
    if (!status) {
      return res.status(404).json({ error: "Webhook delivery not found" });
    }
    
    res.json({
      delivery,
      ...JSON.parse(status),
      timestamp: new Date().toISOString()
    });
  } catch (error) {
    res.status(500).json({
      error: error.message,
      timestamp: new Date().toISOString()
    });
  }
});

function verifySignature(req) {
  if (!WEBHOOK_SECRET) {
    safeLog("Warning: WEBHOOK_SECRET not configured - accepting all webhooks");
    return true; // nothing to verify against
  }
  
  const signature = req.headers["x-hub-signature-256"] || "";
  if (!signature) {
    safeLog("Missing webhook signature header");
    return false;
  }
  
  if (!req.rawBody) {
    safeLog("Missing raw body for signature verification");
    return false;
  }
  
  try {
    const hmac = crypto.createHmac("sha256", WEBHOOK_SECRET);
    const digest = "sha256=" + hmac.update(req.rawBody).digest("hex");
    // Use timing-safe compare
    const isValid = crypto.timingSafeEqual(Buffer.from(digest), Buffer.from(signature));
    
    if (!isValid) {
      safeLog("Webhook signature mismatch - potential security issue");
    }
    
    return isValid;
  } catch (error) {
    safeLog("Error verifying webhook signature:", error.message);
    return false;
  }
}

app.post("/webhook", async (req, res) => {
  const startTime = Date.now();
  const event = req.headers["x-github-event"];
  const delivery = req.headers["x-github-delivery"];
  
  // Enhanced security validation
  if (WEBHOOK_SECRET && !verifySignature(req)) {
    safeLog(`Webhook signature verification failed for delivery: ${delivery}`);
    webhookStats.failed++;
    return res.status(401).json({ 
      error: "Invalid signature", 
      delivery: delivery,
      timestamp: new Date().toISOString()
    });
  }

  // Validate required headers
  if (!event) {
    safeLog(`Missing x-github-event header for delivery: ${delivery}`);
    webhookStats.failed++;
    return res.status(400).json({ 
      error: "Missing event type header",
      delivery: delivery 
    });
  }

  // Validate payload
  if (!req.body || typeof req.body !== 'object') {
    safeLog(`Invalid payload for delivery: ${delivery}`);
    webhookStats.failed++;
    return res.status(400).json({ 
      error: "Invalid payload format",
      delivery: delivery 
    });
  }

  safeLog(`Received webhook: ${event} (delivery: ${delivery})`);

  try {
    // Queue webhook for processing
    const webhookData = {
      event,
      payload: req.body,
      delivery,
      timestamp: new Date().toISOString(),
      headers: {
        'x-github-event': event,
        'x-github-delivery': delivery,
        'x-github-hook-id': req.headers['x-github-hook-id'],
        'x-github-hook-installation-target-id': req.headers['x-github-hook-installation-target-id']
      }
    };

    await queueWebhookForProcessing(webhookData);
    
    webhookStats.queued++;
    const processingTime = Date.now() - startTime;
    
    safeLog(`Webhook queued successfully: ${event} (${processingTime}ms)`);
    
    return res.status(202).json({
      message: "Webhook accepted and queued for processing",
      delivery: delivery,
      event: event,
      timestamp: new Date().toISOString(),
      processing_time_ms: processingTime
    });
    
  } catch (error) {
    webhookStats.failed++;
    safeLog(`Error queuing webhook ${event}:`, error.message);
    
    return res.status(500).json({
      error: "Internal server error",
      delivery: delivery,
      message: "Failed to queue webhook for processing"
    });
  }
// Queue webhook for processing with Redis
async function queueWebhookForProcessing(webhookData) {
  const queueKey = 'github:webhooks:queue';
  const processingKey = 'github:webhooks:processing';
  
  try {
    // Ensure Redis connection
    if (!redisClient.isOpen) {
      await redisClient.connect();
    }
    
    // Add webhook to queue with priority based on event type
    const priority = getWebhookPriority(webhookData.event);
    const queueItem = {
      ...webhookData,
      priority,
      queuedAt: Date.now()
    };
    
    // Use Redis sorted set for priority queue
    await redisClient.zAdd(queueKey, {
      score: priority,
      value: JSON.stringify(queueItem)
    });
    
    // Store processing metadata
    await redisClient.hSet(processingKey, webhookData.delivery, JSON.stringify({
      status: 'queued',
      queuedAt: Date.now(),
      event: webhookData.event
    }));
    
    safeLog(`Webhook queued with priority ${priority}: ${webhookData.event}`);
    
  } catch (error) {
    safeLog('Error queuing webhook:', error.message);
    throw error;
  }
}

// Get webhook priority (lower number = higher priority)
function getWebhookPriority(event) {
  const priorities = {
    'pull_request': 1,
    'issues': 2,
    'push': 3,
    'repository': 4,
    'release': 5,
    'workflow_run': 6,
    'check_run': 7,
    'deployment': 8
  };
  
  return priorities[event] || 10;
}
  
  try {
    // Update processing status
    if (redisClient.isOpeneployment': 8
  };
  
  return priorities[event] || 10;
}
      await redisClient.hSet(processingKey, delivery, JSON.stringify({
        status: 'processing',
        startedAt: Date.now(),
        event: event
      }));
    }
    
    safeLog(`Processing webhook: ${event} (delivery: ${delivery})`);
    
    // Route to appropriate handler based on event type
    const result = await routeWebhookEvent(event, payload, delivery);
    
    // Update success status
    if (redisClient.isOpen) {
      await redisClient.hSet(processingKey, delivery, JSON.stringify({
        status: 'completed',
        completedAt: Date.now(),
        event: event,
        result: result
      }));
    }
    
    webhookStats.processed++;
    webhookStats.lastProcessed = new Date().toISOString();
    
    safeLog(`Webhook processed successfully: ${event} (delivery: ${delivery})`);
    
  } catch (error) {
    webhookStats.failed++;
    
    // Update error status
    if (redisClient.isOpen) {
      await redisClient.hSet(processingKey, delivery, JSON.stringify({
        status: 'failed',
        failedAt: Date.now(),
        event: event,
        error: error.message
      }));
    }
    
    safeLog(`Error processing webhook ${event} (delivery: ${delivery}):`, error.message);
    throw error;
  }
}

// Route webhook events to appropriate handlers
async function routeWebhookEvent(event, payload, delivery) {
  switch (event) {
    case 'pull_request':
      return await handlePullRequestEvent(payload, delivery);
    
    case 'issues':
      return await handleIssuesEvent(payload, delivery);
    
    case 'push':
      return await handlePushEvent(payload, delivery);
    
    case 'repository':
      return await handleRepositoryEvent(payload, delivery);
    
    case 'release':
      return await handleReleaseEvent(payload, delivery);
    
    case 'workflow_run':
      return await handleWorkflowRunEvent(payload, delivery);
    
    case 'check_run':
      return await handleCheckRunEvent(payload, delivery);
    
    case 'deployment':
      return await handleDeploymentEvent(payload, delivery);
    
    default:
      safeLog(`Unhandled webhook event: ${event} (delivery: ${delivery})`);
      return { status: 'ignored', reason: 'unhandled_event_type' };
  }
}

// Handle pull request events
async function handlePullRequestEvent(payload, delivery) {
  const pr = payload.pull_request;
  const action = payload.action;
  
  safeLog(`Processing PR webhook: #${pr?.number} action=${action} (delivery: ${delivery})`);
  
  if (action === "opened" || action === "reopened" || action === "synchronize") {
    const result = await analyzePRWithAI(pr, payload.repository);
    return { status: 'processed', action, pr_number: pr.number, result };
  }
  
  return { status: 'ignored', reason: 'unhandled_pr_action', action };
}

// Handle issues events
async function handleIssuesEvent(payload, delivery) {
  const issue = payload.issue;
  const action = payload.action;
  
  safeLog(`Processing issue webhook: #${issue?.number} action=${action} (delivery: ${delivery})`);
  
  if (action === "opened" || action === "reopened") {
    const result = await analyzeIssueWithAI(issue, payload.repository);
    return { status: 'processed', action, issue_number: issue.number, result };
  }
  
  return { status: 'ignored', reason: 'unhandled_issue_action', action };
}

// Handle push events
async function handlePushEvent(payload, delivery) {
  safeLog(`Processing push webhook: ${payload.ref} (delivery: ${delivery})`);
  // Add push event handling logic here
  return { status: 'processed', ref: payload.ref, commits: payload.commits?.length || 0 };
}

// Handle repository events
async function handleRepositoryEvent(payload, delivery) {
  safeLog(`Processing repository webhook: ${payload.action} (delivery: ${delivery})`);
  // Add repository event handling logic here
  return { status: 'processed', action: payload.action };
}

// Handle release events
async function handleReleaseEvent(payload, delivery) {
  safeLog(`Processing release webhook: ${payload.action} (delivery: ${delivery})`);
  // Add release event handling logic here
  return { status: 'processed', action: payload.action, tag: payload.release?.tag_name };
}

// Handle workflow run events
async function handleWorkflowRunEvent(payload, delivery) {
  safeLog(`Processing workflow run webhook: ${payload.action} (delivery: ${delivery})`);
  // Add workflow run handling logic here
  return { status: 'processed', action: payload.action, workflow: payload.workflow_run?.name };
}

// Handle check run events
async function handleCheckRunEvent(payload, delivery) {
  safeLog(`Processing check run webhook: ${payload.action} (delivery: ${delivery})`);
  // Add check run handling logic here
  return { status: 'processed', action: payload.action, check: payload.check_run?.name };
}

// Handle deployment events
async function handleDeploymentEvent(payload, delivery) {
  safeLog(`Processing deployment webhook: ${payload.action} (delivery: ${delivery})`);
  // Add deployment handling logic here
  return { status: 'processed', action: payload.action, environment: payload.deployment?.environment };
}// Background webhook queue processor
class WebhookQueueProcessor {
  constructor() {
    this.isProcessing = false;
    this.processingInterval = null;
  }
  
  async start() {
    if (this.isProcessing) return;
    
    this.isProcessing = true;
    safeLog('Starting webhook queue processor...');
    
    // Process queue every 2 seconds
    this.processingInterval = setInterval(async () => {
      await this.processQueue();
    }, 2000);
  }
  
  async stop() {
    if (this.processingInterval) {
      clearInterval(this.processingInterval);
      this.processingInterval = null;
    }
    this.isProcessing = false;
    safeLog('Webhook queue processor stopped');
  }
  
  async processQueue() {
    if (!redisClient.isOpen) return;
    
    try {
      const queueKey = 'github:webhooks:queue';
      
      // Get highest priority item from queue (lowest score)
      const items = await redisClient.zRangeWithScores(queueKey, 0, 0);
      
      if (items.length === 0) return; // Queue is empty
      
      const webhookData = JSON.parse(items[0].value);
      
      // Remove from queue
      await redisClient.zRem(queueKey, items[0].value);
      
      // Process the webhook
      await processWebhookAsync(webhookData);
      
    } catch (error) {
      safeLog('Error processing webhook queue:', error.message);
    }
  }
}

const queueProcessor = new WebhookQueueProcessor();

// Initialize the application
async function initializeApp() {
  try {
    // Connect to Redis
    if (!redisClient.isOpen) {
      await redisClient.connect();
      safeLog('Redis connected successfully');
    }
    
    // Start queue processor
    await queueProcessor.start();
    
    // Graceful shutdown handling
    process.on('SIGTERM', async () => {
      safeLog('Received SIGTERM, shutting down gracefully...');
      await queueProcessor.stop();
      await redisClient.quit();
      process.exit(0);
    });
    
    process.on('SIGINT', async () => {
      safeLog('Received SIGINT, shutting down gracefully...');
      await queueProcessor.stop();
      await redisClient.quit();
      process.exit(0);
    });
    
  } catch (error) {
    safeLog('Error initializing application:', error.message);
  }
}
  if (!ENABLE_AI_ANALYSIS) {
    safeLog(`AI analysis disabled for PR #${pr.number}`);
    return;
  }

  try {
    safeLog(`Starting AI analysis for PR #${pr.number}`);
    
    // Get file changes
    const files = await octokit.rest.pulls.listFiles({
      owner: repository.owner.login,
      repo: repository.name,
      pull_number: pr.number
    });

    const prData = {
      ...pr,
      files: files.data
    };

    // Get AI analysis
    const analysis = await aiService.analyzePR(prData);
    safeLog(`AI analysis completed for PR #${pr.number}:`, {
      risk: analysis.riskLevel,
      priority: analysis.priority,
      recommendation: analysis.recommendation
    });

    // Add labels based on AI analysis
    if (TOKEN && analysis.riskLevel !== 'low') {
      await addLabelsToePR(repository, pr.number, analysis);
    }

    // Generate and post review comment if high risk
    if (TOKEN && (analysis.riskLevel === 'high' || analysis.riskLevel === 'critical')) {
      await postAIReviewComment(repository, pr.number, prData, analysis);
    }

  } catch (error) {
    safeLog(`AI analysis failed for PR #${pr.number}:`, error.message);
  }
}

async function analyzeIssueWithAI(issue, repository) {
  if (!ENABLE_AI_ANALYSIS) {
    safeLog(`AI analysis disabled for issue #${issue.number}`);
    return;
  }

  try {
    safeLog(`Starting AI analysis for issue #${issue.number}`);
    
    const analysis = await aiService.analyzeIssue(issue);
    safeLog(`AI analysis completed for issue #${issue.number}:`, {
      type: analysis.type,
      priority: analysis.priority,
      complexity: analysis.complexity
    });

    // Add labels based on AI analysis
    if (TOKEN && analysis.suggestedLabels?.length > 0) {
      await addLabelsToIssue(repository, issue.number, analysis);
    }

  } catch (error) {
    safeLog(`AI analysis failed for issue #${issue.number}:`, error.message);
  }
}

async function addLabelsToePR(repository, prNumber, analysis) {
  try {
    const labels = [];
    
    // Risk level labels
    if (analysis.riskLevel === 'high') labels.push('high-risk');
    if (analysis.riskLevel === 'critical') labels.push('critical-risk');
    
    // Priority labels
    if (analysis.priority === 'high') labels.push('high-priority');
    if (analysis.priority === 'urgent') labels.push('urgent');
    
    // AI generated label
    if (analysis.aiGenerated) labels.push('ai-analyzed');

    if (labels.length > 0) {
      await octokit.rest.issues.addLabels({
        owner: repository.owner.login,
        repo: repository.name,
        issue_number: prNumber,
        labels
      });
      safeLog(`Added labels to PR #${prNumber}:`, labels);
    }
  } catch (error) {
    safeLog(`Failed to add labels to PR #${prNumber}:`, error.message);
  }
}

async function addLabelsToIssue(repository, issueNumber, analysis) {
  try {
    const labels = [...(analysis.suggestedLabels || [])];
    
    // Priority labels
    if (analysis.priority === 'high') labels.push('high-priority');
    if (analysis.priority === 'urgent') labels.push('urgent');
    
    // Complexity labels
    if (analysis.complexity === 'complex') labels.push('complex');
    
    // AI generated label
    if (analysis.aiGenerated) labels.push('ai-analyzed');

    if (labels.length > 0) {
      await octokit.rest.issues.addLabels({
        owner: repository.owner.login,
        repo: repository.name,
        issue_number: issueNumber,
        labels
      });
      safeLog(`Added labels to issue #${issueNumber}:`, labels);
    }
  } catch (error) {
    safeLog(`Failed to add labels to issue #${issueNumber}:`, error.message);
  }
}

async function postAIReviewComment(repository, prNumber, prData, analysis) {
  try {
    const comment = await aiService.generateReviewComment(prData, analysis);
    
    await octokit.rest.issues.createComment({
      owner: repository.owner.login,
      repo: repository.name,
      issue_number: prNumber,
      body: comment
    });
    
    safeLog(`Posted AI review comment on PR #${prNumber}`);
  } catch (error) {
    safeLog(`Failed to post AI comment on PR #${prNumber}:`, error.message);
  }
}

async function promoteDraftIfDesired(owner, repo, pr) {
  if (!PROMOTE_DRAFTS) return;
  if (!pr.draft) return;
  if (!TOKEN) {
    safeLog(`Skipping draft promotion for #${pr.number}: no token available`);
    return;
  }
  try {
    safeLog(`Promoting draft PR #${pr.number} -> ready for review`);
    await octokit.rest.pulls.update({
      owner, repo,
      pull_number: pr.number,
      draft: false
    });
  } catch (err) {
    safeLog(`Failed to promote #${pr.number}: ${err.message || err}`);
  }
}

async function managePRsOnce() {
  if (!REPO) {
    safeLog("No GITHUB_REPOSITORY configured. Skipping PR management.");
    return;
  }
  const [owner, repo] = REPO.split("/");
  if (!owner || repo) {
    safeLog("Malformed GITHUB_REPOSITORY, expected owner/repo:", REPO);
    return;
  }

  try {
    const resp = await octokit.rest.pulls.list({ owner, repo, state: "open", per_page: 50 });
    const pulls = resp.data || [];
    safeLog(`managePRs: found ${pulls.length} open PRs for ${REPO}`);

    for (const pr of pulls) {
      try {
        // Example policy: optionally promote drafts (configurable), otherwise log
        if (pr.draft) {
          safeLog(`Found draft #${pr.number} - draft=${pr.draft}`);
          await promoteDraftIfDesired(owner, repo, pr);
        }

        // Enhanced AI-powered analysis for PRs that haven't been analyzed recently
        if (ENABLE_AI_ANALYSIS && !pr.draft) {
          await performScheduledAIAnalysis(owner, repo, pr);
        }

        // Example: re-check combined status and log failing PRs
        try {
          const status = await octokit.rest.repos.getCombinedStatusForRef({
            owner, repo, ref: pr.head.sha
          });
          if (status.data.state === "failure" || status.data.state === "error") {
            safeLog(`PR #${pr.number} checks failing: ${status.data.state}`);
            // Potentially add label or comment - avoid making changes without policy
          }
        } catch (innerErr) {
          // Non-fatal
          safeLog(`Failed to fetch combined status for #${pr.number}: ${innerErr.message || innerErr}`);
        }

      } catch (prErr) {
        safeLog(`Error handling PR #${pr.number}: ${prErr.message || prErr}`);
      }
    }
  } catch (err) {
    safeLog("managePRs error:", err.message || err);
  }
}

async function performScheduledAIAnalysis(owner, repo, pr) {
  try {
    // Check if PR was recently analyzed (avoid re-analyzing too frequently)
    const comments = await octokit.rest.issues.listComments({
      owner, repo,
      issue_number: pr.number,
      per_page: 10
    });

    const hasRecentAIComment = comments.data.some(comment => 
      comment.body.includes('generated by the GitHub PR management system') &&
      new Date(comment.created_at) > new Date(Date.now() - 24 * 60 * 60 * 1000) // 24 hours
    );

    if (hasRecentAIComment) {
      return; // Skip if recently analyzed
    }

    // Get file changes for analysis
    const files = await octokit.rest.pulls.listFiles({
      owner, repo,
      pull_number: pr.number
    });

    const prData = {
      ...pr,
      files: files.data
    };

    // Perform AI analysis
    const analysis = await aiService.analyzePR(prData);
    
    // Only take action for high-risk PRs to avoid noise
    if (analysis.riskLevel === 'high' || analysis.riskLevel === 'critical') {
      await addLabelsToePR({ owner: { login: owner }, name: repo }, pr.number, analysis);
      
      if (analysis.concerns.length > 0) {
        await postAIReviewComment({ owner: { login: owner }, name: repo }, pr.number, prData, analysis);
      }
    }

    safeLog(`Scheduled AI analysis completed for PR #${pr.number}: ${analysis.riskLevel} risk`);
    
  } catch (error) {
    safeLog(`Scheduled AI analysis failed for PR #${pr.number}:`, error.message);
  }
}

// Background webhook queue processor
class WebhookQueueProcessor {
  constructor() {
    this.isProcessing = false;
    this.processingInterval = null;
  }
  
  async start() {
    if (this.isProcessing) return;
    
    this.isProcessing = true;
    safeLog('Starting webhook queue processor...');
    
    // Process queue every 2 seconds
    this.processingInterval = setInterval(async () => {
      await this.processQueue();
    }, 2000);
  }
  
  async stop() {
    if (this.processingInterval) {
      clearInterval(this.processingInterval);
      this.processingInterval = null;
    }
    this.isProcessing = false;
    safeLog('Webhook queue processor stopped');
  }
  
  async processQueue() {
    if (!redisClient.isOpen) return;
    
    try {
      const queueKey = 'github:webhooks:queue';
      
      // Get highest priority item from queue (lowest score)
      const items = await redisClient.zRangeWithScores(queueKey, 0, 0);
      
      if (items.length === 0) return; // Queue is empty
      
      const webhookData = JSON.parse(items[0].value);
      
      // Remove from queue
      await redisClient.zRem(queueKey, items[0].value);
      
      // Process the webhook
      await processWebhookAsync(webhookData);
      
    } catch (error) {
      safeLog('Error processing webhook queue:', error.message);
    }
  }
}

const queueProcessor = new WebhookQueueProcessor();

// Initialize the application
async function initializeApp() {
  try {
    // Connect to Redis
    if (!redisClient.isOpen) {
      await redisClient.connect();
      safeLog('Redis connected successfully');
    }
    
    // Start queue processor
    await queueProcessor.start();
    
    // Graceful shutdown handling
    process.on('SIGTERM', async () => {
      safeLog('Received SIGTERM, shutting down gracefully...');
      await queueProcessor.stop();
      await redisClient.quit();
      process.exit(0);
    });
    
    process.on('SIGINT', async () => {
      safeLog('Received SIGINT, shutting down gracefully...');
      await queueProcessor.stop();
      await redisClient.quit();
      process.exit(0);
    });
    
  } catch (error) {
    safeLog('Error initializing application:', error.message);
  }
}

async function analyzePRWithAI(pr, repository) {
  if (!ENABLE_AI_ANALYSIS) {
    safeLog(`AI analysis disabled for PR #${pr.number}`);
    return { status: 'disabled', reason: 'AI analysis disabled' };
  }

  try {
    const prData = {
      number: pr.number,
      title: pr.title,
      body: pr.body,
      diff_url: pr.diff_url,
      patch_url: pr.patch_url,
      commits: pr.commits,
      additions: pr.additions,
      deletions: pr.deletions,
      changed_files: pr.changed_files,
      mergeable: pr.mergeable,
      draft: pr.draft
    };

    const analysis = await aiService.analyzePR(prData);
    
    if (analysis && analysis.labels && analysis.labels.length > 0) {
      await addLabelsIfNeeded(pr.number, analysis.labels, repository);
    }

    if (analysis && analysis.reviewComment) {
      await addReviewComment(pr.number, analysis.reviewComment, repository);
    }

    return analysis;
  } catch (error) {
    safeLog(`AI analysis failed for PR #${pr.number}:`, error.message);
    return { status: 'error', error: error.message };
  }
}

async function analyzeIssueWithAI(issue, repository) {
  if (!ENABLE_AI_ANALYSIS) {
    safeLog(`AI analysis disabled for issue #${issue.number}`);
    return { status: 'disabled', reason: 'AI analysis disabled' };
  }

  try {
    const issueData = {
      number: issue.number,
      title: issue.title,
      body: issue.body,
      labels: issue.labels?.map(l => l.name) || [],
      state: issue.state,
      assignees: issue.assignees?.map(a => a.login) || []
    };

    const analysis = await aiService.analyzeIssue(issueData);
    
    if (analysis && analysis.labels && analysis.labels.length > 0) {
      await addLabelsIfNeeded(issue.number, analysis.labels, repository, 'issue');
    }

    return analysis;
  } catch (error) {
    safeLog(`AI analysis failed for issue #${issue.number}:`, error.message);
    return { status: 'error', error: error.message };
  }
}

async function addLabelsIfNeeded(number, labels, repository, type = 'pr') {
  if (!TOKEN || !labels || labels.length === 0) return;

  try {
    const [owner, repo] = repository.full_name.split('/');
    
    if (type === 'pr') {
      await octokit.rest.issues.addLabels({
        owner,
        repo,
        issue_number: number,
        labels
      });
    } else {
      await octokit.rest.issues.addLabels({
        owner,
        repo,
        issue_number: number,
        labels
      });
    }
    
    safeLog(`Added labels to ${type} #${number}:`, labels.join(', '));
  } catch (error) {
    safeLog(`Failed to add labels to ${type} #${number}:`, error.message);
  }
}

async function addReviewComment(prNumber, comment, repository) {
  if (!TOKEN || !comment) return;

  try {
    const [owner, repo] = repository.full_name.split('/');
    
    await octokit.rest.issues.createComment({
      owner,
      repo,
      issue_number: prNumber,
      body: comment
    });
    
    safeLog(`Added AI review comment to PR #${prNumber}`);
  } catch (error) {
    safeLog(`Failed to add review comment to PR #${prNumber}:`, error.message);
  }
}

// Run managePRs every 5 minutes with initial warm-up
(async () => {
  safeLog("Starting GitHub PR Manager with AI integration...");
  safeLog(`AI Analysis: ${ENABLE_AI_ANALYSIS ? 'ENABLED' : 'DISABLED'}`);
  safeLog(`AI Service URL: ${AI_SERVICE_URL}`);

  await managePRsOnce();
  setInterval(managePRsOnce, 5 * 60 * 1000); // 5 minutes
})();app.listen(PORT, async () => {
  safeLog(`GitHub PR Manager with AI listening on port ${PORT} for ${REPO || "no repo configured"}`);
  safeLog(`AI Integration: ${ENABLE_AI_ANALYSIS ? 'ENABLED' : 'DISABLED'}`);
  
  // Initialize the application
  await initializeApp();
});